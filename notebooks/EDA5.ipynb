{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from src.exception import CustomException\n",
    "from src.logger import logging\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "import s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataIngestionConfig:\n",
    "    #image_meta_data_path:   str=os.path.join('artifacts', 'abo-images-small', 'images', 'metadata')\n",
    "    #listing_meta_data_path: str=os.path.join('artifacts', 'abo-listings', 'listings', 'metadata')\n",
    "    listing_meta_data_path = \"s3://amazon-berkeley-objects/listings/metadata/\"\n",
    "    #save_json_path:         str=os.path.join('artifacts', 'dataset.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_pref = ['0','1','2','3','4','5','6','7','8','9','a','b','c','d','e','f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_json(\"s3://amazon-berkeley-objects/listings/metadata/listings_1.json.gz\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing = []\n",
    "for prefix in file_name_pref:\n",
    "    data = pd.read_json(f\"s3://amazon-berkeley-objects/listings/metadata/listings_{prefix}.json.gz\", lines=True)\n",
    "    \n",
    "    listing.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_meta = pd.concat(listing, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>bullet_point</th>\n",
       "      <th>color</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_number</th>\n",
       "      <th>model_year</th>\n",
       "      <th>product_type</th>\n",
       "      <th>style</th>\n",
       "      <th>...</th>\n",
       "      <th>item_weight</th>\n",
       "      <th>material</th>\n",
       "      <th>fabric_type</th>\n",
       "      <th>color_code</th>\n",
       "      <th>product_description</th>\n",
       "      <th>spin_id</th>\n",
       "      <th>3dmodel_id</th>\n",
       "      <th>pattern</th>\n",
       "      <th>finish_type</th>\n",
       "      <th>item_shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'language_tag': 'nl_NL', 'value': 'find.'}]</td>\n",
       "      <td>[{'language_tag': 'nl_NL', 'value': 'Schoen in...</td>\n",
       "      <td>[{'language_tag': 'nl_NL', 'value': 'Veelkleur...</td>\n",
       "      <td>B06X9STHNG</td>\n",
       "      <td>[{'language_tag': 'nl_NL', 'value': 'Amazon-me...</td>\n",
       "      <td>[{'language_tag': 'nl_NL', 'value': '37753'}]</td>\n",
       "      <td>[{'value': '12-05-04'}]</td>\n",
       "      <td>[{'value': 2017}]</td>\n",
       "      <td>[{'value': 'SHOES'}]</td>\n",
       "      <td>[{'language_tag': 'nl_NL', 'value': 'Gesloten-...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'language_tag': 'es_MX', 'value': 'AmazonBas...</td>\n",
       "      <td>[{'language_tag': 'es_MX', 'value': 'White Pow...</td>\n",
       "      <td>[{'language_tag': 'es_MX', 'value': 'White Pow...</td>\n",
       "      <td>B07P8ML82R</td>\n",
       "      <td>[{'language_tag': 'es_MX', 'value': '22\" Botto...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'value': 'AB5013-R22-10'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'value': 'HARDWARE'}]</td>\n",
       "      <td>[{'language_tag': 'es_MX', 'value': '10 pares'}]</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'normalized_value': {'unit': 'pounds', 'valu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               brand  \\\n",
       "0      [{'language_tag': 'nl_NL', 'value': 'find.'}]   \n",
       "1  [{'language_tag': 'es_MX', 'value': 'AmazonBas...   \n",
       "\n",
       "                                        bullet_point  \\\n",
       "0  [{'language_tag': 'nl_NL', 'value': 'Schoen in...   \n",
       "1  [{'language_tag': 'es_MX', 'value': 'White Pow...   \n",
       "\n",
       "                                               color     item_id  \\\n",
       "0  [{'language_tag': 'nl_NL', 'value': 'Veelkleur...  B06X9STHNG   \n",
       "1  [{'language_tag': 'es_MX', 'value': 'White Pow...  B07P8ML82R   \n",
       "\n",
       "                                           item_name  \\\n",
       "0  [{'language_tag': 'nl_NL', 'value': 'Amazon-me...   \n",
       "1  [{'language_tag': 'es_MX', 'value': '22\" Botto...   \n",
       "\n",
       "                                      model_name  \\\n",
       "0  [{'language_tag': 'nl_NL', 'value': '37753'}]   \n",
       "1                                            NaN   \n",
       "\n",
       "                   model_number         model_year             product_type  \\\n",
       "0       [{'value': '12-05-04'}]  [{'value': 2017}]     [{'value': 'SHOES'}]   \n",
       "1  [{'value': 'AB5013-R22-10'}]                NaN  [{'value': 'HARDWARE'}]   \n",
       "\n",
       "                                               style  ...  \\\n",
       "0  [{'language_tag': 'nl_NL', 'value': 'Gesloten-...  ...   \n",
       "1   [{'language_tag': 'es_MX', 'value': '10 pares'}]  ...   \n",
       "\n",
       "                                         item_weight material fabric_type  \\\n",
       "0                                                NaN      NaN         NaN   \n",
       "1  [{'normalized_value': {'unit': 'pounds', 'valu...      NaN         NaN   \n",
       "\n",
       "  color_code product_description spin_id 3dmodel_id pattern finish_type  \\\n",
       "0        NaN                 NaN     NaN        NaN     NaN         NaN   \n",
       "1        NaN                 NaN     NaN        NaN     NaN         NaN   \n",
       "\n",
       "  item_shape  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listing_meta.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    def __init__(self):\n",
    "        self.ingestion_config=DataIngestionConfig()\n",
    "    \n",
    "    def initiate_data_ingestion(self):\n",
    "        #logging.info(\"Data Ingestion - started\")\n",
    "        try:\n",
    "            listing = []\n",
    "            for file in os.listdir(DataIngestionConfig.listing_meta_data_path):\n",
    "                if file.endswith('.gz'):\n",
    "                    file_path = os.path.join(DataIngestionConfig.listing_meta_data_path, file)\n",
    "                    with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "                        data = pd.read_json(f, lines=True)\n",
    "                        listing.append(data)\n",
    "           \n",
    "            listing_meta = pd.concat(listing, ignore_index=True)\n",
    "            return listing_meta\n",
    "        #     logging.info(\"Data Ingestion - file loading - completed\")\n",
    "\n",
    "        #     def func_in_en_us_(x):\n",
    "        #         if isinstance(x, list):  # Check if x is a list before iterating\n",
    "        #             us_texts = [item[\"value\"] for item in x if item[\"language_tag\"] == \"en_US\"]\n",
    "        #             return us_texts[0] if us_texts else None\n",
    "        #         else:\n",
    "        #             return None  # Handle cases where x is not a list (e.g., a float)\n",
    "                        \n",
    "        #     listing_meta = listing_meta.assign(brand_in_en_us=listing_meta.brand.apply(func_in_en_us_))\n",
    "        #     listing_meta = listing_meta.assign(bullet_point_in_en_us=listing_meta.bullet_point.apply(func_in_en_us_))\n",
    "        #     listing_meta = listing_meta.assign(color_in_en_us=listing_meta.color.apply(func_in_en_us_))\n",
    "        #     listing_meta = listing_meta.assign(fabric_type_in_en_us=listing_meta.fabric_type.apply(func_in_en_us_))\n",
    "        #     listing_meta = listing_meta.assign(finish_type_in_en_us=listing_meta.finish_type.apply(func_in_en_us_))\n",
    "        #     listing_meta = listing_meta.assign(item_keywords_in_en_us=listing_meta.item_keywords.apply(func_in_en_us_))\n",
    "        #     listing_meta = listing_meta.assign(item_name_in_en_us=listing_meta.item_name.apply(func_in_en_us_))\n",
    "        #     listing_meta = listing_meta.assign(item_shape_in_en_us=listing_meta.item_shape.apply(func_in_en_us_))\n",
    "        #     listing_meta = listing_meta.assign(material_in_en_us=listing_meta.material.apply(func_in_en_us_))\n",
    "        #     listing_meta = listing_meta.assign(model_name_in_en_us=listing_meta.model_name.apply(func_in_en_us_))\n",
    "        #     listing_meta = listing_meta.assign(pattern_in_en_us=listing_meta.pattern.apply(func_in_en_us_))\n",
    "        #     listing_meta = listing_meta.assign(product_description_in_en_us=listing_meta.product_description.apply(func_in_en_us_)) \n",
    "               \n",
    "        #     listing_meta = listing_meta[~listing_meta.item_name_in_en_us.isna()]\n",
    "            \n",
    "        #     logging.info(\"Data Ingestion - processing listing meta data  - completed\")\n",
    "\n",
    "        #     print(f\" number products with US English title: {len(listing_meta)}\")\n",
    "\n",
    "        #     image_meta = pd.read_csv(DataIngestionConfig.image_meta_data_path + \"/images.csv.gz\")\n",
    "        #     dataset = listing_meta.merge(image_meta, left_on=\"main_image_id\", right_on=\"image_id\")\n",
    "\n",
    "        #     dataset = dataset.drop_duplicates(subset=['item_id'], keep='first')\n",
    "\n",
    "        #     def func_image_path_(image_ids):\n",
    "        #         if isinstance(image_ids, list):\n",
    "        #             image_paths = [image_meta[image_meta[\"image_id\"] == image_id][\"path\"].to_list()[0] for image_id in image_ids]\n",
    "        #             return image_paths if image_paths else None\n",
    "        #         else:\n",
    "        #             return None\n",
    "            \n",
    "        #     dataset = dataset.assign(other_image_id_path=dataset.other_image_id.apply(func_image_path_))\n",
    "\n",
    "        #     logging.info(\"Data Ingestion - processing image meta data - completed\")\n",
    "\n",
    "        #     dataset = dataset.drop(columns=['brand', 'bullet_point', 'color', 'fabric_type', 'finish_type', 'item_keywords', \n",
    "        #                                     'item_name', 'item_shape', 'material', 'model_name', 'model_number', 'pattern', \n",
    "        #                                     'product_description', 'style', 'node', 'model_year', 'item_dimensions', 'item_weight',\n",
    "        #                                     'image_id', 'main_image_id', 'other_image_id'])\n",
    "\n",
    "        #     print(f\" number of matching products with US English title and image: {dataset.shape[0]}\")\n",
    "\n",
    "        #     dataset.to_json(self.ingestion_config.save_json_path, orient='records')\n",
    "\n",
    "        #     logging.info(\"Data Ingestion - completed\")\n",
    "            \n",
    "        #     return self.ingestion_config.save_json_path                \n",
    "            \n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "CustomException",
     "evalue": "Error occured in script [/var/folders/rv/z_0yz9v11p94xxdj7r_1w4vc0000gn/T/ipykernel_18570/2987284521.py] line number [9] error message [[Errno 2] No such file or directory: 's3://amazon-berkeley-objects/listings/metadata/']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 9\u001b[0m, in \u001b[0;36mDataIngestion.initiate_data_ingestion\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m listing \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDataIngestionConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisting_meta_data_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.gz\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 's3://amazon-berkeley-objects/listings/metadata/'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCustomException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m obj\u001b[38;5;241m=\u001b[39mDataIngestion()\n\u001b[0;32m----> 2\u001b[0m json_file \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_data_ingestion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 76\u001b[0m, in \u001b[0;36mDataIngestion.initiate_data_ingestion\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#     logging.info(\"Data Ingestion - file loading - completed\")\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#     def func_in_en_us_(x):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m#     return self.ingestion_config.save_json_path                \u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CustomException(e, sys)\n",
      "\u001b[0;31mCustomException\u001b[0m: Error occured in script [/var/folders/rv/z_0yz9v11p94xxdj7r_1w4vc0000gn/T/ipykernel_18570/2987284521.py] line number [9] error message [[Errno 2] No such file or directory: 's3://amazon-berkeley-objects/listings/metadata/']"
     ]
    }
   ],
   "source": [
    "obj=DataIngestion()\n",
    "json_file = obj.initiate_data_ingestion()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
